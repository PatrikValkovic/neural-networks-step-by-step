{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "So far I used NumPy library for all the computations. This library performs all the computations on CPU. If you check the code once again, you may notice most of the computations can be done independently. So far, we had operations that are same for each input (mainly the activation functions) or linear combination - the dense layer. Although CPU can perform these operations in parallel (something called vectorization), procesor ability to do this is limited.\n",
    "\n",
    "On the other hand, most modern computers have not only the processor, but some kind of graphical processing units as well. Purpose of the the GPU is to perform many operations in parallel - for example for each pixel on your screen. Moderns GPU have in order of thousands computing processors called CUDA cores (todays NVIDIA most performant GPU is NVIDIA Tesla V100 with 5120 CUDA cores and 16GB of memory). The performance of these CUDA cores are much smaller compared to the CPU, but their advantage is their amount. The most common CPUs have around 8 cores, with maximum of 64 cores of that have AMD ThreadRipper. Still, in comparison to 5120 CUDA cores in NVIDIA Tesla V100, the difference is massive.\n",
    "\n",
    "Now up to the point - both matrix multiplication or activation functions can be computed in parallel. When we have hundreds (or even thousands) of neurons in the hidden layer, we may utilize GPU to perform these operations in parallel and this speed up the whole training. \n",
    "\n",
    "Right now there are two main frameworks for neural networks - [TensorFlow](https://www.tensorflow.org) and [PyTorch](https://pytorch.org). In this notebook, I will focus on the PyTorch framework from Facebook, mainly because it is more similar to the architecture I designed. In the following notebook, I will describe the TensorFlow framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Both PyTorch and TensorFlow supports both CPU and GPU. By default, all computations are done on the CPU. If you want to utilize the GPU, you need to install additional tools and libraries. I will briefly describe what needs to be done, for more detailed instructions see [documentation page](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "First thing you need is graphical card. The recommend is NVIDIA graphical card (the frameworks are optimized mainly for them). I don't have access to AMD graphical card, so rest of the text will be focues only on NVIDIA graphical cards only.\n",
    "\n",
    "Install the [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) from the NVIDIA's website. Before installation check, what version of CUDA Toolkit is supported by the PyTorch library. At the time of writing this, the last supported version of CUDA toolking by PyTorch is 10.2, although the latest CUDA toolkit version is 11.1. Make sure you have the correct version installed.\n",
    "\n",
    "Install Python (althoug you probably already done that). Once again, check your version of Python is supported. Right now I am running Python 3.7, versions from 3.6 up to 3.8 should be supported. This may change even during writing this, so please check your Python version will work.\n",
    "\n",
    "Install the library. Unlike other sources, I can't recommend using Anaconda installation and I prefer to using PyTorch using `pip`. All you need is to execute `pip install torch torchvision` on your command line (we will use torchvision later).\n",
    "\n",
    "Make sure your installation works. First let's try simple code to test PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408],\n",
      "        [0.1332, 0.9346, 0.5936],\n",
      "        [0.8694, 0.5677, 0.7411]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, make sure the torch see the GPU device and can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Tensor\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing, sklearn.datasets, sklearn.model_selection\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropyLoss:\n",
    "    def __call__(self, target, predicted):\n",
    "        indices = np.arange(len(target))\n",
    "        return -np.log(np.maximum(predicted[indices,target], 1e-15))\n",
    "    \n",
    "    def gradient(self, target, predicted):\n",
    "        grad = np.zeros((len(target), 10))\n",
    "        indices = np.arange(len(target))\n",
    "        grad[indices,target] = -1 / predicted[indices,target]\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        inputs = inputs - np.max(inputs)\n",
    "        return np.exp(inputs) / np.sum(np.exp(inputs), axis=-1)[:,np.newaxis]\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        outputs = self(inputs)  # examples, classes\n",
    "        examples, classes = outputs.shape\n",
    "        diag = np.zeros((examples, classes, classes))  # examples, classes, classes\n",
    "        diag[:, np.arange(classes), np.arange(classes)] = outputs # set the diagonal of each example\n",
    "        my_gradient = diag - outputs[:,:,np.newaxis] * outputs[:,np.newaxis,:]  # examples, classes, classes\n",
    "        return np.sum(gradients[:,np.newaxis,:] * my_gradient, axis=2) # examples, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        return 1 / (1 + np.exp(-inputs))\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        outputs = self(inputs)\n",
    "        my_gradient = outputs * (1 - outputs)\n",
    "        return my_gradient * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self,inputs, outputs, random_seed=None):\n",
    "        self._random_state = np.random.RandomState(random_seed)\n",
    "        self._W = self._random_state.uniform(-2,2,size=(inputs, outputs))\n",
    "        self._b = self._random_state.uniform(-2,2,size=(outputs,))\n",
    "        self.params = [self._W, self._b]\n",
    "        self.grads = [np.zeros_like(self._W), np.zeros_like(self._b)]\n",
    "        self._cache = None\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return inputs @ self._W + self._b[np.newaxis,:]\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        # create the cache\n",
    "        if self._cache is None or self._cache.shape[0] != inputs.shape[0]:\n",
    "            self._cache = np.ndarray((inputs.shape[0],inputs.shape[1], gradients.shape[1]))\n",
    "        # gradient in respect to W\n",
    "        w_grad = np.multiply(inputs[:,:,np.newaxis], gradients[:,np.newaxis,:], out=self._cache)  # examples, inputs, outputs\n",
    "        np.add(self.grads[0], np.sum(w_grad, axis=0), out=self.grads[0])  # inputs, outputs\n",
    "        # gradient in respect to b\n",
    "        b_grad = gradients  # examples, outputs\n",
    "        np.add(self.grads[1], np.sum(b_grad, axis=0), out=self.grads[1])  # outputs\n",
    "        # gradient in respect to inputs\n",
    "        in_grad = np.multiply(self._W[np.newaxis,:,:], gradients[:,np.newaxis,:], out=self._cache)  # examples, inputs, outputs\n",
    "        #in_grad = np.add(in_grad, np.sign(self._b)[np.newaxis, np.newaxis, :], out=self._cache)  # examples, inputs, outputs\n",
    "        return np.sum(in_grad, axis=2) # examples, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.random.randint(0,10,size=(3,), dtype=int)\n",
    "vals = np.random.uniform(size=(3,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = DenseLayer(7,13,42)\n",
    "dense2 = DenseLayer(13,10,42)\n",
    "sig = SigmoidLayer()\n",
    "soft = SoftmaxLayer()\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "\n",
    "d1 = dense1(vals)\n",
    "a1 = sig(d1)\n",
    "d2 = dense2(a1)\n",
    "a2 = soft(d2)\n",
    "l = loss(target, a2)\n",
    "\n",
    "l_grad = loss.gradient(target, a2)\n",
    "a2_grad = soft.gradient(d2, l_grad)\n",
    "d2_grad = dense2.gradient(a1, a2_grad)\n",
    "a1_grad = sig.gradient(d1, d2_grad)\n",
    "d1_grad = dense1.gradient(vals, a1_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1_tf = tf.Variable(dense1._W)\n",
    "b1_tf = tf.Variable(dense1._b)\n",
    "w2_tf = tf.Variable(dense2._W)\n",
    "b2_tf = tf.Variable(dense2._b)\n",
    "target_tf = tf.Variable(target)\n",
    "vals_tf = tf.Variable(vals)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    d1_tf = vals_tf @ w1_tf + b1_tf\n",
    "    a1_tf = tf.math.sigmoid(d1_tf)\n",
    "    d2_tf = a1_tf @ w2_tf + b2_tf\n",
    "    a2_tf = tf.nn.softmax(d2_tf)\n",
    "    l_tf = tf.keras.losses.sparse_categorical_crossentropy(target_tf, a2_tf)\n",
    "\n",
    "l_grad_tf, a2_grad_tf, d2_grad_tf, a1_grad_tf, d1_grad_tf, w1_grad_tf, b1_grad_tf, w2_grad_tf, b2_grad_tf = tape.gradient(l_tf, [a2_tf, d2_tf, a1_tf, d1_tf, vals_tf, w1_tf, b1_tf, w2_tf, b2_tf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "w1_t = torch.tensor(dense1._W, requires_grad=True)\n",
    "b1_t = torch.tensor(dense1._b, requires_grad=True)\n",
    "w2_t = torch.tensor(dense2._W, requires_grad=True)\n",
    "b2_t = torch.tensor(dense2._b, requires_grad=True)\n",
    "target_t = torch.tensor(target, dtype=torch.long)\n",
    "vals_t = torch.tensor(vals, requires_grad=True)\n",
    "\n",
    "d1_t = vals_t @ w1_t + b1_t\n",
    "d1_t.retain_grad()\n",
    "a1_t = torch.sigmoid(d1_t)\n",
    "a1_t.retain_grad()\n",
    "d2_t = a1_t @ w2_t + b2_t\n",
    "d2_t.retain_grad()\n",
    "a2_t = torch.nn.functional.softmax(d2_t, dim=1)\n",
    "a2_t.retain_grad()\n",
    "l_t = torch.nn.functional.nll_loss(torch.log(a2_t), target_t, reduction='none')\n",
    "l_t.backward(torch.ones(l_t.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1\n",
      "[[ 0.6932029   0.12440943  1.6350084  -0.4385792   0.29678732 -2.53289151\n",
      "  -3.62099081 -2.76084936 -0.72306391 -1.33772196  0.21228408  1.0553516\n",
      "   0.10723124]\n",
      " [-0.19377441 -0.53171348  1.24997532 -0.32948138 -0.59951081 -4.39256857\n",
      "  -4.24204798 -1.88886257 -1.25979112 -1.69652151 -0.02766604  0.49136799\n",
      "   0.97723431]\n",
      " [-0.69778271 -1.45381162  1.64622787 -1.85416627  0.82989938 -3.49434065\n",
      "  -4.71753211 -2.2721133  -0.24414888 -0.92795472  0.08874479  0.481691\n",
      "   0.41429437]]\n",
      "tf.Tensor(\n",
      "[[ 0.6932029   0.12440943  1.6350084  -0.4385792   0.29678732 -2.53289151\n",
      "  -3.62099081 -2.76084936 -0.72306391 -1.33772196  0.21228408  1.0553516\n",
      "   0.10723124]\n",
      " [-0.19377441 -0.53171348  1.24997532 -0.32948138 -0.59951081 -4.39256857\n",
      "  -4.24204798 -1.88886257 -1.25979112 -1.69652151 -0.02766604  0.49136799\n",
      "   0.97723431]\n",
      " [-0.69778271 -1.45381162  1.64622787 -1.85416627  0.82989938 -3.49434065\n",
      "  -4.71753211 -2.2721133  -0.24414888 -0.92795472  0.08874479  0.481691\n",
      "   0.41429437]], shape=(3, 13), dtype=float64)\n",
      "tensor([[ 0.6932,  0.1244,  1.6350, -0.4386,  0.2968, -2.5329, -3.6210, -2.7608,\n",
      "         -0.7231, -1.3377,  0.2123,  1.0554,  0.1072],\n",
      "        [-0.1938, -0.5317,  1.2500, -0.3295, -0.5995, -4.3926, -4.2420, -1.8889,\n",
      "         -1.2598, -1.6965, -0.0277,  0.4914,  0.9772],\n",
      "        [-0.6978, -1.4538,  1.6462, -1.8542,  0.8299, -3.4943, -4.7175, -2.2721,\n",
      "         -0.2441, -0.9280,  0.0887,  0.4817,  0.4143]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"d1\")\n",
    "print(d1)\n",
    "print(d1_tf)\n",
    "print(d1_t)\n",
    "\n",
    "print(np.abs(d1 - d1_t.detach().numpy()) < 1e-12)\n",
    "print(np.abs(d1 - d1_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1\n",
      "[[0.66667905 0.5310623  0.83685458 0.39207957 0.57365696 0.07358429\n",
      "  0.02605892 0.05947684 0.32671865 0.20788493 0.55287261 0.74180123\n",
      "  0.52678215]\n",
      " [0.45170741 0.37011734 0.77729559 0.41836682 0.35445562 0.0122178\n",
      "  0.01417432 0.13137421 0.22100985 0.15492012 0.49308393 0.62042864\n",
      "  0.7265591 ]\n",
      " [0.33230401 0.18941565 0.83838058 0.13538447 0.69633365 0.02947369\n",
      "  0.00885804 0.09345901 0.43926418 0.28333984 0.52217165 0.6181471\n",
      "  0.60211714]]\n",
      "tf.Tensor(\n",
      "[[0.66667905 0.5310623  0.83685458 0.39207957 0.57365696 0.07358429\n",
      "  0.02605892 0.05947684 0.32671865 0.20788493 0.55287261 0.74180123\n",
      "  0.52678215]\n",
      " [0.45170741 0.37011734 0.77729559 0.41836682 0.35445562 0.0122178\n",
      "  0.01417432 0.13137421 0.22100985 0.15492012 0.49308393 0.62042864\n",
      "  0.7265591 ]\n",
      " [0.33230401 0.18941565 0.83838058 0.13538447 0.69633365 0.02947369\n",
      "  0.00885804 0.09345901 0.43926418 0.28333984 0.52217165 0.6181471\n",
      "  0.60211714]], shape=(3, 13), dtype=float64)\n",
      "tensor([[0.6667, 0.5311, 0.8369, 0.3921, 0.5737, 0.0736, 0.0261, 0.0595, 0.3267,\n",
      "         0.2079, 0.5529, 0.7418, 0.5268],\n",
      "        [0.4517, 0.3701, 0.7773, 0.4184, 0.3545, 0.0122, 0.0142, 0.1314, 0.2210,\n",
      "         0.1549, 0.4931, 0.6204, 0.7266],\n",
      "        [0.3323, 0.1894, 0.8384, 0.1354, 0.6963, 0.0295, 0.0089, 0.0935, 0.4393,\n",
      "         0.2833, 0.5222, 0.6181, 0.6021]], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"a1\")\n",
    "print(a1)\n",
    "print(a1_tf)\n",
    "print(a1_t)\n",
    "\n",
    "print(np.abs(a1 - a1_t.detach().numpy()) < 1e-12)\n",
    "print(np.abs(a1 - a1_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2\n",
      "[[-2.67020338 -0.19100413 -2.11920083 -0.03316696  0.96553367 -0.14223227\n",
      "  -1.66501519  1.65931148 -0.28927579 -1.58724065]\n",
      " [-1.58243255 -0.61787009 -2.67978935 -0.50374138  1.42582527  0.03625567\n",
      "  -0.72057143  1.53947271 -0.86776417 -1.15894359]\n",
      " [-1.87781046 -0.78600125 -3.07633088 -0.49874809  1.08827325  0.21363996\n",
      "  -0.49899418  1.80610943 -0.68527891 -1.82621801]]\n",
      "tf.Tensor(\n",
      "[[-2.67020338 -0.19100413 -2.11920083 -0.03316696  0.96553367 -0.14223227\n",
      "  -1.66501519  1.65931148 -0.28927579 -1.58724065]\n",
      " [-1.58243255 -0.61787009 -2.67978935 -0.50374138  1.42582527  0.03625567\n",
      "  -0.72057143  1.53947271 -0.86776417 -1.15894359]\n",
      " [-1.87781046 -0.78600125 -3.07633088 -0.49874809  1.08827325  0.21363996\n",
      "  -0.49899418  1.80610943 -0.68527891 -1.82621801]], shape=(3, 10), dtype=float64)\n",
      "tensor([[-2.6702, -0.1910, -2.1192, -0.0332,  0.9655, -0.1422, -1.6650,  1.6593,\n",
      "         -0.2893, -1.5872],\n",
      "        [-1.5824, -0.6179, -2.6798, -0.5037,  1.4258,  0.0363, -0.7206,  1.5395,\n",
      "         -0.8678, -1.1589],\n",
      "        [-1.8778, -0.7860, -3.0763, -0.4987,  1.0883,  0.2136, -0.4990,  1.8061,\n",
      "         -0.6853, -1.8262]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"d2\")\n",
    "print(d2)\n",
    "print(d2_tf)\n",
    "print(d2_t)\n",
    "\n",
    "print(np.abs(d2 - d2_t.detach().numpy()) < 1e-12)\n",
    "print(np.abs(d2 - d2_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2\n",
      "[[0.00583075 0.0695708  0.0101163  0.0814657  0.22115918 0.073048\n",
      "  0.01593207 0.4425974  0.06305916 0.01722064]\n",
      " [0.01644069 0.04313445 0.00548712 0.04834925 0.3329583  0.08296739\n",
      "  0.03892437 0.37303218 0.0335967  0.02510955]\n",
      " [0.01192101 0.03552055 0.00359585 0.04734042 0.2314551  0.09652023\n",
      "  0.04732877 0.47448124 0.03928464 0.01255218]]\n",
      "tf.Tensor(\n",
      "[[0.00583075 0.0695708  0.0101163  0.0814657  0.22115918 0.073048\n",
      "  0.01593207 0.4425974  0.06305916 0.01722064]\n",
      " [0.01644069 0.04313445 0.00548712 0.04834925 0.3329583  0.08296739\n",
      "  0.03892437 0.37303218 0.0335967  0.02510955]\n",
      " [0.01192101 0.03552055 0.00359585 0.04734042 0.2314551  0.09652023\n",
      "  0.04732877 0.47448124 0.03928464 0.01255218]], shape=(3, 10), dtype=float64)\n",
      "tensor([[0.0058, 0.0696, 0.0101, 0.0815, 0.2212, 0.0730, 0.0159, 0.4426, 0.0631,\n",
      "         0.0172],\n",
      "        [0.0164, 0.0431, 0.0055, 0.0483, 0.3330, 0.0830, 0.0389, 0.3730, 0.0336,\n",
      "         0.0251],\n",
      "        [0.0119, 0.0355, 0.0036, 0.0473, 0.2315, 0.0965, 0.0473, 0.4745, 0.0393,\n",
      "         0.0126]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"a2\")\n",
    "print(a2)\n",
    "print(a2_tf)\n",
    "print(a2_t)\n",
    "\n",
    "print(np.abs(a2 - a2_t.detach().numpy()) < 1e-12)\n",
    "print(np.abs(a2 - a2_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "[2.61663848 0.98609058 5.62797351]\n",
      "tf.Tensor([2.61663848 0.98609058 5.62797351], shape=(3,), dtype=float64)\n",
      "tensor([2.6166, 0.9861, 5.6280], dtype=torch.float64,\n",
      "       grad_fn=<NllLossBackward>)\n",
      "[ True  True  True]\n",
      "[ True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"l\")\n",
    "print(l)\n",
    "print(l_tf)\n",
    "print(l_t)\n",
    "\n",
    "print(np.abs(l - l_t.detach().numpy()) < 1e-12)\n",
    "print(np.abs(l - l_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grad\n",
      "[[   0.            0.            0.            0.            0.\n",
      "   -13.6896282     0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.            0.\n",
      "     0.            0.           -2.68073384    0.            0.        ]\n",
      " [   0.            0.         -278.0979848     0.            0.\n",
      "     0.            0.            0.            0.            0.        ]]\n",
      "tf.Tensor(\n",
      "[[   1.            1.            1.            1.            1.\n",
      "   -12.6896282     1.            1.            1.            1.        ]\n",
      " [   1.            1.            1.            1.            1.\n",
      "     1.            1.           -1.68073384    1.            1.        ]\n",
      " [   1.            1.         -277.0979848     1.            1.\n",
      "     1.            1.            1.            1.            1.        ]], shape=(3, 10), dtype=float64)\n",
      "tensor([[   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,  -13.6896,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,   -2.6807,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, -278.0980,    0.0000,    0.0000,    0.0000,\n",
      "            0.0000,    0.0000,    0.0000,    0.0000]], dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss grad\")\n",
    "print(l_grad)\n",
    "print(l_grad_tf)\n",
    "print(a2_t.grad)\n",
    "\n",
    "print(np.abs(l_grad - a2_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(l_grad + 1 - l_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax grad\n",
      "[[ 0.00583075  0.0695708   0.0101163   0.0814657   0.22115918 -0.926952\n",
      "   0.01593207  0.4425974   0.06305916  0.01722064]\n",
      " [ 0.01644069  0.04313445  0.00548712  0.04834925  0.3329583   0.08296739\n",
      "   0.03892437 -0.62696782  0.0335967   0.02510955]\n",
      " [ 0.01192101  0.03552055 -0.99640415  0.04734042  0.2314551   0.09652023\n",
      "   0.04732877  0.47448124  0.03928464  0.01255218]]\n",
      "tf.Tensor(\n",
      "[[ 0.00583075  0.0695708   0.0101163   0.0814657   0.22115918 -0.926952\n",
      "   0.01593207  0.4425974   0.06305916  0.01722064]\n",
      " [ 0.01644069  0.04313445  0.00548712  0.04834925  0.3329583   0.08296739\n",
      "   0.03892437 -0.62696782  0.0335967   0.02510955]\n",
      " [ 0.01192101  0.03552055 -0.99640415  0.04734042  0.2314551   0.09652023\n",
      "   0.04732877  0.47448124  0.03928464  0.01255218]], shape=(3, 10), dtype=float64)\n",
      "tensor([[ 0.0058,  0.0696,  0.0101,  0.0815,  0.2212, -0.9270,  0.0159,  0.4426,\n",
      "          0.0631,  0.0172],\n",
      "        [ 0.0164,  0.0431,  0.0055,  0.0483,  0.3330,  0.0830,  0.0389, -0.6270,\n",
      "          0.0336,  0.0251],\n",
      "        [ 0.0119,  0.0355, -0.9964,  0.0473,  0.2315,  0.0965,  0.0473,  0.4745,\n",
      "          0.0393,  0.0126]], dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Softmax grad\")\n",
    "print(a2_grad)\n",
    "print(a2_grad_tf)\n",
    "print(d2_t.grad)\n",
    "\n",
    "print(np.abs(a2_grad - d2_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(a2_grad - a2_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense2 grad\n",
      "[[ 1.795194    0.93151355 -1.24778256 -1.37444831 -0.69800677 -1.93485727\n",
      "  -0.01335748 -1.45980517  0.72861035  0.07015516  1.66160574 -1.67449081\n",
      "   0.54782942]\n",
      " [-1.43124487 -0.65029031 -0.16471132  1.74729687 -0.32909427  1.0544566\n",
      "  -1.16690022  1.42045241 -0.61270384  0.47027209 -0.28386317  1.18771925\n",
      "  -1.29771763]\n",
      " [-0.6615301  -1.76361014  0.78857692  1.55238034  1.74792935 -2.09704912\n",
      "  -1.09831361  1.48203526  0.74766589 -0.99463539  1.42330229 -1.91921736\n",
      "   1.11034652]]\n",
      "tf.Tensor(\n",
      "[[ 1.795194    0.93151355 -1.24778256 -1.37444831 -0.69800677 -1.93485727\n",
      "  -0.01335748 -1.45980517  0.72861035  0.07015516  1.66160574 -1.67449081\n",
      "   0.54782942]\n",
      " [-1.43124487 -0.65029031 -0.16471132  1.74729687 -0.32909427  1.0544566\n",
      "  -1.16690022  1.42045241 -0.61270384  0.47027209 -0.28386317  1.18771925\n",
      "  -1.29771763]\n",
      " [-0.6615301  -1.76361014  0.78857692  1.55238034  1.74792935 -2.09704912\n",
      "  -1.09831361  1.48203526  0.74766589 -0.99463539  1.42330229 -1.91921736\n",
      "   1.11034652]], shape=(3, 13), dtype=float64)\n",
      "tensor([[ 1.7952,  0.9315, -1.2478, -1.3744, -0.6980, -1.9349, -0.0134, -1.4598,\n",
      "          0.7286,  0.0702,  1.6616, -1.6745,  0.5478],\n",
      "        [-1.4312, -0.6503, -0.1647,  1.7473, -0.3291,  1.0545, -1.1669,  1.4205,\n",
      "         -0.6127,  0.4703, -0.2839,  1.1877, -1.2977],\n",
      "        [-0.6615, -1.7636,  0.7886,  1.5524,  1.7479, -2.0970, -1.0983,  1.4820,\n",
      "          0.7477, -0.9946,  1.4233, -1.9192,  1.1103]], dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense2 grad\")\n",
    "print(d2_grad)\n",
    "print(d2_grad_tf)\n",
    "print(a1_t.grad)\n",
    "\n",
    "print(np.abs(d2_grad - a1_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(d2_grad - d2_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 grad\n",
      "[[ 1.52750198e-02  7.76691649e-02 -3.21886198e-01  9.18826025e-02\n",
      "   3.74755385e-01 -5.48428431e-01  4.39315441e-02  1.69536421e-01\n",
      "   7.02705416e-02  2.69939495e-02]\n",
      " [ 1.14395019e-02  5.96393834e-02 -1.81331273e-01  7.01252747e-02\n",
      "   2.84524163e-01 -4.43279152e-01  3.18323153e-02  9.28693077e-02\n",
      "   5.33641881e-02  2.08162915e-02]\n",
      " [ 2.76531081e-02  1.21528597e-01 -8.22634905e-01  1.45445894e-01\n",
      "   6.37932557e-01 -6.30313156e-01  8.32680913e-02  2.80846200e-01\n",
      "   1.11821394e-01  4.44522202e-02]\n",
      " [ 1.07782770e-02  5.01322410e-02 -1.28635625e-01  5.85779157e-02\n",
      "   2.57346128e-01 -3.15660797e-01  2.89388843e-02 -2.45317404e-02\n",
      "   4.40984818e-02  1.89562342e-02]\n",
      " [ 1.74733446e-02  7.99331747e-02 -6.86081513e-01  9.68357596e-02\n",
      "   4.06058421e-01 -4.35133927e-01  5.58931221e-02  3.62064067e-01\n",
      "   7.54380834e-02  2.75194678e-02]\n",
      " [ 9.81276683e-04  6.69324736e-03 -2.85562615e-02  7.98061398e-03\n",
      "   2.71636935e-02 -6.43506192e-02  3.04287336e-03  3.88927608e-02\n",
      "   6.20850421e-03  1.94391080e-03]\n",
      " [ 4.90575359e-04  2.73898342e-03 -8.48479303e-03  3.22756885e-03\n",
      "   1.25328636e-02 -2.21243787e-02  1.38613897e-03  6.84974335e-03\n",
      "   2.46744852e-03  9.15849609e-04]\n",
      " [ 3.62080301e-03  1.31243204e-02 -9.18003939e-02  1.56215554e-02\n",
      "   7.85275476e-02 -3.52117108e-02  1.04845480e-02 -1.16985641e-02\n",
      "   1.18358030e-02  5.49609141e-03]\n",
      " [ 1.07750412e-02  4.78661202e-02 -4.33166758e-01  5.80969761e-02\n",
      "   2.47513828e-01 -2.42118012e-01  3.45978084e-02  2.14461369e-01\n",
      "   4.52841411e-02  1.66894861e-02]\n",
      " [ 7.13681538e-03  3.12095014e-02 -2.79367900e-01  3.78391911e-02\n",
      "   1.63138053e-01 -1.52498007e-01  2.27523326e-02  1.29318836e-01\n",
      "   2.94447581e-02  1.10264194e-02]\n",
      " [ 1.75551150e-02  7.82805161e-02 -5.11995361e-01  9.36002190e-02\n",
      "   4.07308534e-01 -4.21176358e-01  5.27151299e-02  1.83312874e-01\n",
      "   7.19430009e-02  2.84563296e-02]\n",
      " [ 2.18944697e-02  1.00326475e-01 -6.05015683e-01  1.19691961e-01\n",
      "   5.13706319e-01 -5.76475085e-01  6.52243666e-02  2.32629702e-01\n",
      "   9.19054034e-02  3.61120708e-02]\n",
      " [ 2.21945119e-02  8.93759117e-02 -5.90636213e-01  1.06547743e-01\n",
      "   4.97779676e-01 -3.69904571e-01  6.51710511e-02  6.33165242e-02\n",
      "   8.12823836e-02  3.48729830e-02]]\n",
      "tf.Tensor(\n",
      "[[ 1.52750198e-02  7.76691649e-02 -3.21886198e-01  9.18826025e-02\n",
      "   3.74755385e-01 -5.48428431e-01  4.39315441e-02  1.69536421e-01\n",
      "   7.02705416e-02  2.69939495e-02]\n",
      " [ 1.14395019e-02  5.96393834e-02 -1.81331273e-01  7.01252747e-02\n",
      "   2.84524163e-01 -4.43279152e-01  3.18323153e-02  9.28693077e-02\n",
      "   5.33641881e-02  2.08162915e-02]\n",
      " [ 2.76531081e-02  1.21528597e-01 -8.22634905e-01  1.45445894e-01\n",
      "   6.37932557e-01 -6.30313156e-01  8.32680913e-02  2.80846200e-01\n",
      "   1.11821394e-01  4.44522202e-02]\n",
      " [ 1.07782770e-02  5.01322410e-02 -1.28635625e-01  5.85779157e-02\n",
      "   2.57346128e-01 -3.15660797e-01  2.89388843e-02 -2.45317404e-02\n",
      "   4.40984818e-02  1.89562342e-02]\n",
      " [ 1.74733446e-02  7.99331747e-02 -6.86081513e-01  9.68357596e-02\n",
      "   4.06058421e-01 -4.35133927e-01  5.58931221e-02  3.62064067e-01\n",
      "   7.54380834e-02  2.75194678e-02]\n",
      " [ 9.81276683e-04  6.69324736e-03 -2.85562615e-02  7.98061398e-03\n",
      "   2.71636935e-02 -6.43506192e-02  3.04287336e-03  3.88927608e-02\n",
      "   6.20850421e-03  1.94391080e-03]\n",
      " [ 4.90575359e-04  2.73898342e-03 -8.48479303e-03  3.22756885e-03\n",
      "   1.25328636e-02 -2.21243787e-02  1.38613897e-03  6.84974335e-03\n",
      "   2.46744852e-03  9.15849609e-04]\n",
      " [ 3.62080301e-03  1.31243204e-02 -9.18003939e-02  1.56215554e-02\n",
      "   7.85275476e-02 -3.52117108e-02  1.04845480e-02 -1.16985641e-02\n",
      "   1.18358030e-02  5.49609141e-03]\n",
      " [ 1.07750412e-02  4.78661202e-02 -4.33166758e-01  5.80969761e-02\n",
      "   2.47513828e-01 -2.42118012e-01  3.45978084e-02  2.14461369e-01\n",
      "   4.52841411e-02  1.66894861e-02]\n",
      " [ 7.13681538e-03  3.12095014e-02 -2.79367900e-01  3.78391911e-02\n",
      "   1.63138053e-01 -1.52498007e-01  2.27523326e-02  1.29318836e-01\n",
      "   2.94447581e-02  1.10264194e-02]\n",
      " [ 1.75551150e-02  7.82805161e-02 -5.11995361e-01  9.36002190e-02\n",
      "   4.07308534e-01 -4.21176358e-01  5.27151299e-02  1.83312874e-01\n",
      "   7.19430009e-02  2.84563296e-02]\n",
      " [ 2.18944697e-02  1.00326475e-01 -6.05015683e-01  1.19691961e-01\n",
      "   5.13706319e-01 -5.76475085e-01  6.52243666e-02  2.32629702e-01\n",
      "   9.19054034e-02  3.61120708e-02]\n",
      " [ 2.21945119e-02  8.93759117e-02 -5.90636213e-01  1.06547743e-01\n",
      "   4.97779676e-01 -3.69904571e-01  6.51710511e-02  6.33165242e-02\n",
      "   8.12823836e-02  3.48729830e-02]], shape=(13, 10), dtype=float64)\n",
      "tensor([[ 1.5275e-02,  7.7669e-02, -3.2189e-01,  9.1883e-02,  3.7476e-01,\n",
      "         -5.4843e-01,  4.3932e-02,  1.6954e-01,  7.0271e-02,  2.6994e-02],\n",
      "        [ 1.1440e-02,  5.9639e-02, -1.8133e-01,  7.0125e-02,  2.8452e-01,\n",
      "         -4.4328e-01,  3.1832e-02,  9.2869e-02,  5.3364e-02,  2.0816e-02],\n",
      "        [ 2.7653e-02,  1.2153e-01, -8.2263e-01,  1.4545e-01,  6.3793e-01,\n",
      "         -6.3031e-01,  8.3268e-02,  2.8085e-01,  1.1182e-01,  4.4452e-02],\n",
      "        [ 1.0778e-02,  5.0132e-02, -1.2864e-01,  5.8578e-02,  2.5735e-01,\n",
      "         -3.1566e-01,  2.8939e-02, -2.4532e-02,  4.4098e-02,  1.8956e-02],\n",
      "        [ 1.7473e-02,  7.9933e-02, -6.8608e-01,  9.6836e-02,  4.0606e-01,\n",
      "         -4.3513e-01,  5.5893e-02,  3.6206e-01,  7.5438e-02,  2.7519e-02],\n",
      "        [ 9.8128e-04,  6.6932e-03, -2.8556e-02,  7.9806e-03,  2.7164e-02,\n",
      "         -6.4351e-02,  3.0429e-03,  3.8893e-02,  6.2085e-03,  1.9439e-03],\n",
      "        [ 4.9058e-04,  2.7390e-03, -8.4848e-03,  3.2276e-03,  1.2533e-02,\n",
      "         -2.2124e-02,  1.3861e-03,  6.8497e-03,  2.4674e-03,  9.1585e-04],\n",
      "        [ 3.6208e-03,  1.3124e-02, -9.1800e-02,  1.5622e-02,  7.8528e-02,\n",
      "         -3.5212e-02,  1.0485e-02, -1.1699e-02,  1.1836e-02,  5.4961e-03],\n",
      "        [ 1.0775e-02,  4.7866e-02, -4.3317e-01,  5.8097e-02,  2.4751e-01,\n",
      "         -2.4212e-01,  3.4598e-02,  2.1446e-01,  4.5284e-02,  1.6689e-02],\n",
      "        [ 7.1368e-03,  3.1210e-02, -2.7937e-01,  3.7839e-02,  1.6314e-01,\n",
      "         -1.5250e-01,  2.2752e-02,  1.2932e-01,  2.9445e-02,  1.1026e-02],\n",
      "        [ 1.7555e-02,  7.8281e-02, -5.1200e-01,  9.3600e-02,  4.0731e-01,\n",
      "         -4.2118e-01,  5.2715e-02,  1.8331e-01,  7.1943e-02,  2.8456e-02],\n",
      "        [ 2.1894e-02,  1.0033e-01, -6.0502e-01,  1.1969e-01,  5.1371e-01,\n",
      "         -5.7648e-01,  6.5224e-02,  2.3263e-01,  9.1905e-02,  3.6112e-02],\n",
      "        [ 2.2195e-02,  8.9376e-02, -5.9064e-01,  1.0655e-01,  4.9778e-01,\n",
      "         -3.6990e-01,  6.5171e-02,  6.3317e-02,  8.1282e-02,  3.4873e-02]],\n",
      "       dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"W2 grad\")\n",
    "print(dense2.grads[0])\n",
    "print(w2_grad_tf)\n",
    "print(w2_t.grad)\n",
    "\n",
    "print(np.abs(dense2.grads[0] - w2_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(dense2.grads[0] - w2_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2 grad\n",
      "[ 0.03419245  0.1482258  -0.98080073  0.17715537  0.78557258 -0.74746438\n",
      "  0.10218521  0.29011082  0.1359405   0.05488237]\n",
      "tf.Tensor(\n",
      "[ 0.03419245  0.1482258  -0.98080073  0.17715537  0.78557258 -0.74746438\n",
      "  0.10218521  0.29011082  0.1359405   0.05488237], shape=(10,), dtype=float64)\n",
      "tensor([ 0.0342,  0.1482, -0.9808,  0.1772,  0.7856, -0.7475,  0.1022,  0.2901,\n",
      "         0.1359,  0.0549], dtype=torch.float64)\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"b2 grad\")\n",
    "print(dense2.grads[1])\n",
    "print(b2_grad_tf)\n",
    "print(b2_t.grad)\n",
    "\n",
    "print(np.abs(dense2.grads[1] - b2_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(dense2.grads[1] - b2_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 grad\n",
      "[[ 3.98924590e-01  2.31979600e-01 -1.70358492e-01 -3.27604128e-01\n",
      "  -1.70714762e-01 -1.31898528e-01 -3.39010854e-04 -8.16605402e-02\n",
      "   1.60275022e-01  1.15523655e-02  4.10756395e-01 -3.20718852e-01\n",
      "   1.36564406e-01]\n",
      " [-3.54473304e-01 -1.51602500e-01 -2.85127074e-02  4.25180273e-01\n",
      "  -7.53023082e-02  1.27257332e-02 -1.63055686e-02  1.62094968e-01\n",
      "  -1.05485849e-01  6.15679652e-02 -7.09522149e-02  2.79704251e-01\n",
      "  -2.57818828e-01]\n",
      " [-1.46779012e-01 -2.70780044e-01  1.06851053e-01  1.81714681e-01\n",
      "   3.69605073e-01 -5.99860644e-02 -9.64272822e-03  1.25564583e-01\n",
      "   1.84158452e-01 -2.01969047e-01  3.55125904e-01 -4.53014489e-01\n",
      "   2.66008036e-01]]\n",
      "tf.Tensor(\n",
      "[[ 3.98924590e-01  2.31979600e-01 -1.70358492e-01 -3.27604128e-01\n",
      "  -1.70714762e-01 -1.31898528e-01 -3.39010854e-04 -8.16605402e-02\n",
      "   1.60275022e-01  1.15523655e-02  4.10756395e-01 -3.20718852e-01\n",
      "   1.36564406e-01]\n",
      " [-3.54473304e-01 -1.51602500e-01 -2.85127074e-02  4.25180273e-01\n",
      "  -7.53023082e-02  1.27257332e-02 -1.63055686e-02  1.62094968e-01\n",
      "  -1.05485849e-01  6.15679652e-02 -7.09522149e-02  2.79704251e-01\n",
      "  -2.57818828e-01]\n",
      " [-1.46779012e-01 -2.70780044e-01  1.06851053e-01  1.81714681e-01\n",
      "   3.69605073e-01 -5.99860644e-02 -9.64272822e-03  1.25564583e-01\n",
      "   1.84158452e-01 -2.01969047e-01  3.55125904e-01 -4.53014489e-01\n",
      "   2.66008036e-01]], shape=(3, 13), dtype=float64)\n",
      "tensor([[ 3.9892e-01,  2.3198e-01, -1.7036e-01, -3.2760e-01, -1.7071e-01,\n",
      "         -1.3190e-01, -3.3901e-04, -8.1661e-02,  1.6028e-01,  1.1552e-02,\n",
      "          4.1076e-01, -3.2072e-01,  1.3656e-01],\n",
      "        [-3.5447e-01, -1.5160e-01, -2.8513e-02,  4.2518e-01, -7.5302e-02,\n",
      "          1.2726e-02, -1.6306e-02,  1.6209e-01, -1.0549e-01,  6.1568e-02,\n",
      "         -7.0952e-02,  2.7970e-01, -2.5782e-01],\n",
      "        [-1.4678e-01, -2.7078e-01,  1.0685e-01,  1.8171e-01,  3.6961e-01,\n",
      "         -5.9986e-02, -9.6427e-03,  1.2556e-01,  1.8416e-01, -2.0197e-01,\n",
      "          3.5513e-01, -4.5301e-01,  2.6601e-01]], dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"a1 grad\")\n",
    "print(a1_grad)\n",
    "print(a1_grad_tf)\n",
    "print(d1_t.grad)\n",
    "\n",
    "print(np.abs(a1_grad - d1_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(a1_grad - a1_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 grad\n",
      "[[-0.90645419 -0.54740991  0.62821749 -0.87863711  1.46949315 -0.22028005\n",
      "   0.02940728]\n",
      " [ 0.72578925  0.17482157 -0.7996455  -0.4114022  -0.1683685  -0.43896257\n",
      "   0.71792223]\n",
      " [-1.74109686  0.448638    1.09240371 -0.36257421 -0.34664971  0.04732065\n",
      "   0.77180218]]\n",
      "tf.Tensor(\n",
      "[[-0.90645419 -0.54740991  0.62821749 -0.87863711  1.46949315 -0.22028005\n",
      "   0.02940728]\n",
      " [ 0.72578925  0.17482157 -0.7996455  -0.4114022  -0.1683685  -0.43896257\n",
      "   0.71792223]\n",
      " [-1.74109686  0.448638    1.09240371 -0.36257421 -0.34664971  0.04732065\n",
      "   0.77180218]], shape=(3, 7), dtype=float64)\n",
      "tensor([[-0.9065, -0.5474,  0.6282, -0.8786,  1.4695, -0.2203,  0.0294],\n",
      "        [ 0.7258,  0.1748, -0.7996, -0.4114, -0.1684, -0.4390,  0.7179],\n",
      "        [-1.7411,  0.4486,  1.0924, -0.3626, -0.3466,  0.0473,  0.7718]],\n",
      "       dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 grad\")\n",
    "print(d1_grad)\n",
    "print(d1_grad_tf)\n",
    "print(vals_t.grad)\n",
    "\n",
    "print(np.abs(d1_grad - vals_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(d1_grad - d1_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 grad\n",
      "[[-4.69966628e-02 -7.93710735e-02 -4.96189443e-02  1.30556705e-01\n",
      "   3.89463792e-02 -8.19961017e-02 -1.22817259e-02  9.42785067e-02\n",
      "   1.02682363e-01 -5.01196917e-02  3.11530440e-01 -2.07661811e-01\n",
      "   5.12921236e-02]\n",
      " [-2.78820512e-01 -2.81225729e-01 -1.68399980e-04  4.02753089e-01\n",
      "   1.95388246e-01 -9.81253619e-02 -2.32633057e-02  2.22445723e-01\n",
      "   1.40018492e-01 -1.22949540e-01  4.29755276e-01 -2.95744807e-01\n",
      "   6.92175285e-02]\n",
      " [-1.48135435e-01 -1.86512024e-01  1.13651319e-02  2.23834970e-01\n",
      "   1.67334297e-01 -7.17055956e-02 -1.40083551e-02  1.35449939e-01\n",
      "   1.21334020e-01 -1.05095011e-01  3.22668515e-01 -2.68656253e-01\n",
      "   1.00730522e-01]\n",
      " [-1.41758607e-01 -1.72937080e-01 -6.11886503e-02  2.76827599e-01\n",
      "   9.29796377e-02 -1.23183241e-01 -2.13697672e-02  1.76618786e-01\n",
      "   1.54797658e-01 -8.88543564e-02  4.81371573e-01 -3.13424676e-01\n",
      "   6.85093156e-02]\n",
      " [-9.28067378e-02 -1.12475885e-01 -7.68296616e-02  2.14331156e-01\n",
      "   2.96540493e-02 -1.10114657e-01 -1.82221652e-02  1.41035841e-01\n",
      "   1.24142387e-01 -5.43775921e-02  4.10227305e-01 -2.40880122e-01\n",
      "   3.40536783e-02]\n",
      " [ 8.21137016e-02 -6.00654770e-02 -2.69042725e-02 -1.58981276e-02\n",
      "   1.28886065e-01 -1.04563711e-01 -7.79390086e-03  5.10779269e-02\n",
      "   1.85739987e-01 -1.11147868e-01  4.25406900e-01 -4.16215030e-01\n",
      "   2.07432424e-01]\n",
      " [-2.25665672e-01 -2.13114520e-01 -8.71882284e-03  3.25861621e-01\n",
      "   1.29948699e-01 -7.51253925e-02 -1.86632815e-02  1.76184697e-01\n",
      "   9.76477606e-02 -8.36305786e-02  3.21854552e-01 -2.00040063e-01\n",
      "   2.99589763e-02]]\n",
      "tf.Tensor(\n",
      "[[-4.69966628e-02 -7.93710735e-02 -4.96189443e-02  1.30556705e-01\n",
      "   3.89463792e-02 -8.19961017e-02 -1.22817259e-02  9.42785067e-02\n",
      "   1.02682363e-01 -5.01196917e-02  3.11530440e-01 -2.07661811e-01\n",
      "   5.12921236e-02]\n",
      " [-2.78820512e-01 -2.81225729e-01 -1.68399980e-04  4.02753089e-01\n",
      "   1.95388246e-01 -9.81253619e-02 -2.32633057e-02  2.22445723e-01\n",
      "   1.40018492e-01 -1.22949540e-01  4.29755276e-01 -2.95744807e-01\n",
      "   6.92175285e-02]\n",
      " [-1.48135435e-01 -1.86512024e-01  1.13651319e-02  2.23834970e-01\n",
      "   1.67334297e-01 -7.17055956e-02 -1.40083551e-02  1.35449939e-01\n",
      "   1.21334020e-01 -1.05095011e-01  3.22668515e-01 -2.68656253e-01\n",
      "   1.00730522e-01]\n",
      " [-1.41758607e-01 -1.72937080e-01 -6.11886503e-02  2.76827599e-01\n",
      "   9.29796377e-02 -1.23183241e-01 -2.13697672e-02  1.76618786e-01\n",
      "   1.54797658e-01 -8.88543564e-02  4.81371573e-01 -3.13424676e-01\n",
      "   6.85093156e-02]\n",
      " [-9.28067378e-02 -1.12475885e-01 -7.68296616e-02  2.14331156e-01\n",
      "   2.96540493e-02 -1.10114657e-01 -1.82221652e-02  1.41035841e-01\n",
      "   1.24142387e-01 -5.43775921e-02  4.10227305e-01 -2.40880122e-01\n",
      "   3.40536783e-02]\n",
      " [ 8.21137016e-02 -6.00654770e-02 -2.69042725e-02 -1.58981276e-02\n",
      "   1.28886065e-01 -1.04563711e-01 -7.79390086e-03  5.10779269e-02\n",
      "   1.85739987e-01 -1.11147868e-01  4.25406900e-01 -4.16215030e-01\n",
      "   2.07432424e-01]\n",
      " [-2.25665672e-01 -2.13114520e-01 -8.71882284e-03  3.25861621e-01\n",
      "   1.29948699e-01 -7.51253925e-02 -1.86632815e-02  1.76184697e-01\n",
      "   9.76477606e-02 -8.36305786e-02  3.21854552e-01 -2.00040063e-01\n",
      "   2.99589763e-02]], shape=(7, 13), dtype=float64)\n",
      "tensor([[-4.6997e-02, -7.9371e-02, -4.9619e-02,  1.3056e-01,  3.8946e-02,\n",
      "         -8.1996e-02, -1.2282e-02,  9.4279e-02,  1.0268e-01, -5.0120e-02,\n",
      "          3.1153e-01, -2.0766e-01,  5.1292e-02],\n",
      "        [-2.7882e-01, -2.8123e-01, -1.6840e-04,  4.0275e-01,  1.9539e-01,\n",
      "         -9.8125e-02, -2.3263e-02,  2.2245e-01,  1.4002e-01, -1.2295e-01,\n",
      "          4.2976e-01, -2.9574e-01,  6.9218e-02],\n",
      "        [-1.4814e-01, -1.8651e-01,  1.1365e-02,  2.2383e-01,  1.6733e-01,\n",
      "         -7.1706e-02, -1.4008e-02,  1.3545e-01,  1.2133e-01, -1.0510e-01,\n",
      "          3.2267e-01, -2.6866e-01,  1.0073e-01],\n",
      "        [-1.4176e-01, -1.7294e-01, -6.1189e-02,  2.7683e-01,  9.2980e-02,\n",
      "         -1.2318e-01, -2.1370e-02,  1.7662e-01,  1.5480e-01, -8.8854e-02,\n",
      "          4.8137e-01, -3.1342e-01,  6.8509e-02],\n",
      "        [-9.2807e-02, -1.1248e-01, -7.6830e-02,  2.1433e-01,  2.9654e-02,\n",
      "         -1.1011e-01, -1.8222e-02,  1.4104e-01,  1.2414e-01, -5.4378e-02,\n",
      "          4.1023e-01, -2.4088e-01,  3.4054e-02],\n",
      "        [ 8.2114e-02, -6.0065e-02, -2.6904e-02, -1.5898e-02,  1.2889e-01,\n",
      "         -1.0456e-01, -7.7939e-03,  5.1078e-02,  1.8574e-01, -1.1115e-01,\n",
      "          4.2541e-01, -4.1622e-01,  2.0743e-01],\n",
      "        [-2.2567e-01, -2.1311e-01, -8.7188e-03,  3.2586e-01,  1.2995e-01,\n",
      "         -7.5125e-02, -1.8663e-02,  1.7618e-01,  9.7648e-02, -8.3631e-02,\n",
      "          3.2185e-01, -2.0004e-01,  2.9959e-02]], dtype=torch.float64)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True]]\n"
     ]
    }
   ],
   "source": [
    "print(\"W1 grad\")\n",
    "print(dense1.grads[0])\n",
    "print(w1_grad_tf)\n",
    "print(w1_t.grad)\n",
    "\n",
    "print(np.abs(dense1.grads[0] - w1_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(dense1.grads[0] - w1_grad_tf.numpy()) < 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 grad\n",
      "[-0.10232773 -0.19040294 -0.09202015  0.27929083  0.123588   -0.17915886\n",
      " -0.02628731  0.20599901  0.23894762 -0.12884872  0.69493008 -0.49402909\n",
      "  0.14475361]\n",
      "tf.Tensor(\n",
      "[-0.10232773 -0.19040294 -0.09202015  0.27929083  0.123588   -0.17915886\n",
      " -0.02628731  0.20599901  0.23894762 -0.12884872  0.69493008 -0.49402909\n",
      "  0.14475361], shape=(13,), dtype=float64)\n",
      "tensor([-0.1023, -0.1904, -0.0920,  0.2793,  0.1236, -0.1792, -0.0263,  0.2060,\n",
      "         0.2389, -0.1288,  0.6949, -0.4940,  0.1448], dtype=torch.float64)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"b1 grad\")\n",
    "print(dense1.grads[1])\n",
    "print(b1_grad_tf)\n",
    "print(b1_t.grad)\n",
    "\n",
    "print(np.abs(dense1.grads[1] - b1_t.grad.detach().numpy()) < 1e-12)\n",
    "print(np.abs(dense1.grads[1] - b1_grad_tf.numpy()) < 1e-12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

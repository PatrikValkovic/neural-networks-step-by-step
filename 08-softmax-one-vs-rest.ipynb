{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing, sklearn.datasets, sklearn.model_selection\n",
    "from progressbar import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the previous notebook, I briefly showed one-vs-rest classification technique and normalization of the distribution. We may put this normalization after the sigmoid activation functions - that exactly, what softmax is suppose to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Formally, we may define the softmax as follow:\n",
    "\n",
    "$$\n",
    "softmax(\\pmb{x})_i = \\frac{e^{x_i}}{\\sum_k e^{x_k}}\n",
    "$$\n",
    "\n",
    "In other words, we apply exponential to each input of the softmax and then normalize the probability distribution.\n",
    "\n",
    "Note that softmax is just a generalization of the sigmoid activation.\n",
    "\n",
    "$$\n",
    "softmax(x, 0) = \\frac{e^x}{e^x + e^0} = \\frac{e^x}{e^x + 1} \\cdot \\frac{e^{-x}}{e^{-x}} = \\frac{e^{x-x}}{e^{x-x} + e^{-x}} = \\frac{e^0}{e^0 + e^{-x}} = \\frac{1}{1+e^{-x}} = \\sigma(x)\n",
    "$$\n",
    "\n",
    "Now, when we have the formula, it is easy to implement the sigmoid in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But why bother with sigmoid and not just normalize the outputs of sigmoids? It turns out, we may get better numerical properties if we join sigmoids and normalization into one \"layer\". Thanks to the following equation.\n",
    "\n",
    "$$\n",
    "softmax(\\pmb{x}+c)_i=\\frac{e^{x_i+c}}{\\sum_k e^{x_k+c}} = \\frac{e^c}{e^c} \\cdot \\frac{e^{x_i}}{\\sum_k e^{x_k}} = softmax(\\pmb{x})_i\n",
    "$$\n",
    "\n",
    "The danger in the softmax is the exponents when the divisor can become too big for float values and as a result, become infinity. However, we may set $c=max(\\pmb{x})$ and as all the scalars are negative or zero, there would be no overflow. Cases, where the divisor becomes zero are much more unlikely and even if some scalars are so small, that they are round to zero because of the float precision, it doesn't matter for users to distinguish between their actual value and zero. \n",
    "\n",
    "This way, we have our modified softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "\n",
    "Before we move on, we need to know how to compute the gradient. That is not that easy as with softmax, as we have multiple inputs and multiple outputs. You may try it by hand if you wish.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial softmax(\\pmb{x})_i}{\\partial x_j} = \\frac{\\partial \\frac{e^{x_i}}{\\sum_k e^{x_k}}}{\\partial x_j}\n",
    "$$\n",
    "\n",
    "There are three indices! Moreover, this is derivative only with respect to one input variable. We need to compute the gradient of every output with respect to every input. I don't want to dig too much into the math, you can see [[1]](#Bibliography) if you wanna know more. In the end, the gradient pops out, so we may implement it.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial softmax(\\pmb{x})_i}{\\partial x_j} = \n",
    "\\begin{cases}\n",
    "    softmax(\\pmb{x})_j - softmax(\\pmb{x})_j \\cdot softmax(\\pmb{x})_i & \\text{if } i = j \\\\\n",
    "    0 - softmax(\\pmb{x})_j \\cdot softmax(\\pmb{x})_i & \\text{if } i \\neq j \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "You may notice something strange - the gradient is a table. Remember, we compute the gradient of each output with respect to each input. That need's to be a table. But we want only gradients with respect to the inputs - we need to sum the gradients over the outputs, the same way, as we sum gradients of multiple examples. I won't show the implementation just yet, as I believe it would be more helpful to view the code and the explanation in the bigger picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mentioned **layer** a while ago. The fact is, the softmax is really a layer, how we understand them in the context of neural networks. We will implement our first simple neural networks in the very next notebook. It took us eight notebooks, but we finally have enough knowledge to do that. However, we need some refactoring of the code before we can do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring\n",
    "\n",
    "Let's start with the **layer** implementation itself. Maybe I should tell first, what the layer is. During the neural network training (we may think about the logistic regression as about a simple neural network) we are exploiting the chain rule. You may remember from school the chain rule.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f(g(h(x)))}{\\partial x} = \\frac{\\partial f(g(h(x)))}{\\partial g(h(x))} \\cdot \\frac{\\partial g(h(x))}{\\partial h(x)} \\cdot \\frac{\\partial h(x)}{\\partial x}\n",
    "$$\n",
    "\n",
    "This is not different from our model, remember that loss of logistic regression was written as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\sigma(\\pmb{x}\\pmb{w})\n",
    "$$\n",
    "\n",
    "And we need to update the weights.\n",
    "\n",
    "$$\n",
    "\\frac{\\mathcal{L}}{\\partial \\pmb{w}} = \\frac{\\partial \\mathcal{L}}{\\partial \\sigma} \\cdot \\frac{\\partial \\sigma}{\\partial \\pmb{x}\\pmb{w}} \\cdot \\frac{\\partial \\pmb{x}\\pmb{w}}{\\partial \\pmb{w}}\n",
    "$$\n",
    "\n",
    "Each part of the gradient will be one layer. We will use the same layers for neural networks later on. We already implemented some - for example the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropyLoss:\n",
    "    def __call__(self, target, predicted):\n",
    "        indices = np.arange(len(target))\n",
    "        return -np.log(np.maximum(predicted[indices,target], 1e-15))\n",
    "    \n",
    "    def gradient(self, target, predicted):\n",
    "        grad = np.zeros((len(target), 10))\n",
    "        indices = np.arange(len(target))\n",
    "        grad[indices,target] = -1 / np.maximum(predicted[indices,target], 1e-15)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, that the layer accepts the output of the previous layer (in this case in shape `(batchsize, classes)`) and it returns its gradient with respect to its input - again in the shape `(batchsize,classes)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use the same approach - let's now implement the sigmoid layer. It takes inputs and applies the sigmoid activation function on each of them. It is simple to implement it right away, but there is one problem. If you carefully look at the chain rule, the gradients are multiplied by the gradients of the following layer. In other words, by computing the gradient of the sigmoid, we need to compute this:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathcal{L}}{\\partial \\pmb{w}} = \\frac{\\partial \\mathcal{L}}{\\partial \\sigma} \\cdot \\frac{\\partial \\sigma}{\\partial \\pmb{x}\\pmb{w}}\n",
    "$$\n",
    "\n",
    "As a result, the gradient function doesn't accept only the layer's input, but gradient from the following layer as well. Now we may implement the sigmoid activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer:\n",
    "    def __call__(self, inputs):\n",
    "        return 1 / (1 + np.exp(-inputs))\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        outputs = self(inputs)\n",
    "        my_gradient = outputs * (1 - outputs)\n",
    "        return my_gradient * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the softmax layer. This case is a bit complicated, as the gradient is not a vector, but a table. In general, most layers that have multiple inputs and multiple outputs will generate gradient table (note that for each example), as it needs to compute gradient of each output with respect to each input. The sigmoid activation layer, and activation layers in general, are exceptions. Each output corresponds to one input and as such the inputs don't interfere. You may look at it from the other side, the gradient of output $i$ in respect to input $j$ is zero if $i \\neq j$. That results in a table full of zeros except for diagonals.\n",
    "\n",
    "But let's return back to the softmax layer. We already implemented it above, but only for a single example. We need to generalize it for a batch of examples. The only thing we need to make sure about is to divide inputs in the correct axis - the generalization is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_softmax(inputs):\n",
    "    inputs = inputs - np.max(inputs)\n",
    "    return np.exp(inputs) / np.sum(np.exp(inputs), axis=-1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the gradient, the formula is above. It would be simpler to rewrite it in the matrix form, so we may implement it in the numpy. Notice that the only difference is on the diagonal (when $i - j$) where we add additional term. In a matrix notation it results in following equation (as you may see in [[1]](#Bibliography) as well):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial softmax(\\pmb{x})}{\\partial \\pmb{x}} = \n",
    "\\begin{pmatrix}\n",
    "o_1 & 0 & \\dots & 0 \\\\ \n",
    "0 & o_2 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & o_k\n",
    "\\end{pmatrix}\n",
    "-\n",
    "\\begin{pmatrix}\n",
    "o_1 o_1 & o_1 o_2 & \\dots & o_1 o_k \\\\ \n",
    "o_2 o_1 & o_2 o_2 o_2 & \\dots & o_2 o_k \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "o_k o_1 & o_k o_2 & \\dots & o_k o_k\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The vector $\\pmb{o}$ is the output of softmax $softmax(\\pmb{x})=\\pmb{o}$. Notice the symmetry of the matrices, we will exploit it in a minute. If we have variable `outputs` that contains the output of the softmax function, we may implement the matrix notations to the NumPy very simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_gradient(inputs):\n",
    "    outputs = softmax(inputs)\n",
    "    return np.diag(outputs) - outputs @ outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three things we need to deal with before we may continue. Firstly, the problem is the matrix of the gradient - remember we want the gradient with respect to the inputs of the softmax, so we may pass it to the previous layer (remember the chain rule I showed you before). Now we have a matrix - gradient of each output with respect to each input. All we need is to sum up the gradients over the outputs. As a result, we get a vector, that represents the \"accumulated\" gradient with respect to each input. I may formulate it in other way around - we receive a gradient of how much we want to shift each output. Each output tells us, how much it wants to shift it's input so the output is shifted the correct way (and therefore we get the matrix). In the end, we want to satisfy all the outputs - we sum the effect of each output on the inputs and as a result, we get the vector that represents the gradient with respect to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_gradient(inputs):\n",
    "    outputs = softmax(inputs)\n",
    "    return np.sum(np.diag(outputs) - outputs @ outputs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second problem that I didn't account for yet is the gradient from the next layer. Once again, remember the chain rule. The gradient of the softmax need's to be multiplied with the gradient of the following layer (for example the cross-entropy loss). We just need to make sure, we multiply the gradient along a correct axis. We think about the matrix above as a gradient of outputs with respect to the inputs, in other words at index $i,j$ is gradient of output $j$ with respect to input $i$, we need to multiply each row and then sum the gradients over columns. As I pointed out, the matrix is in this case symmetric and as such doesn't matter in which way we multiply it - we just need to make sure, we multiply it in the different axis that we are summing it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_gradient(inputs, gradients):\n",
    "    outputs = softmax(inputs)\n",
    "    my_gradient = np.diag(outputs) - outputs @ outputs\n",
    "    return np.sum(gradients[np.newaxis,:] * my_gradient, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the third and the last problem - we didn't count with the batches. The code above won't work for multiple examples, as with softmax, we need to generalize it. We can't rely on vector and matrix multiplication, as we have higher dimensional objects. The code is bellow and it gets a bit nasty, I add comments about the shapes of NumPy arrays, so you may better understand it. I wish I could write it more readable, but this is as far as I could get.\n",
    "\n",
    "There are two more attributes - `params` and `grads`. We don't need them yet and I will talk about them in a while, for now just ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        inputs = inputs - np.max(inputs)\n",
    "        return np.exp(inputs) / np.sum(np.exp(inputs), axis=-1)[:,np.newaxis]\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        outputs = self(inputs)  # examples, classes\n",
    "        examples, classes = outputs.shape\n",
    "        diag = np.zeros((examples, classes, classes))  # examples, classes, classes\n",
    "        diag[:, np.arange(classes), np.arange(classes)] = outputs # set the diagonal of each example\n",
    "        my_gradient = diag - outputs[:,:,np.newaxis] * outputs[:,np.newaxis,:]  # examples, classes, classes\n",
    "        return np.sum(gradients[:,np.newaxis,:] * my_gradient, axis=2) # examples, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense layer\n",
    "\n",
    "Now it is time for our last layer. If you remember, the logistic regression had vector of weights, that was multiplied with the example vector (or matrix when we had batch). For the one-vs-rest approach, we had multiple logistic regressions and when we were processing the examples, we need to pass it through every neuron. As turns out, we can join the weights of all the neurons together into the weights matrix.\n",
    "\n",
    "$$\n",
    "\\mathbb{X}\\mathbb{W}\n",
    "$$\n",
    "\n",
    "Moreover, we may export the bias explicitly and get rid of the additional $1$ that we needed to pad the examples with. As a result, we may express the whole loss of multiclass logistic regression in the following formula.\n",
    "\n",
    "$$\n",
    "\\text{CrossEntropy}(\\text{softmax}(\\mathbb{X}\\mathbb{W}+\\mathbb{b}))\n",
    "$$\n",
    "\n",
    "The layer, that is responsible for the linear combination (the $\\mathbb{X}\\mathbb{W}+\\mathbb{b}$) is called **dense layer** or **fully-connected layer**. That is exactly what we will now focus on.\n",
    "\n",
    "We have the formula for calculating the output of the layer. Now we need to compute the gradient. As we have only linearities, the gradients are simple as well.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbb{X}\\mathbb{W}+\\mathbb{b}}{\\partial \\mathbb{W}} = \\mathbb{X} \\\\\n",
    "\\frac{\\partial \\mathbb{X}\\mathbb{W}+\\mathbb{b}}{\\partial \\mathbb{b}} = sign(\\mathbb{b}) \\\\\n",
    "\\frac{\\partial \\mathbb{X}\\mathbb{W}+\\mathbb{b}}{\\partial \\mathbb{X}} = \\mathbb{W}^T\n",
    "$$\n",
    "\n",
    "But now we have three gradients - with respect to weights, to bias, and to inputs. All previous layers don't have learning parameters, so we need only derivatives with respect to the inputs. Now, we need also derivatives with respect to the weights and bias. That's why I defined the `params` and `grads` attributes. Attribute `params` is list of learnable parameters and `grads` attributes contain gradients of these parameters. We will use them during the optimization process.\n",
    "\n",
    "From the implementation of view, both the forward and backward pass is very simple, we just need to make sure the axis align. As with the softmax, I put comments about the implementation and about the resulting shape of the variable. Let's see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self,inputs, outputs, random_seed=None):\n",
    "        self._random_state = np.random.RandomState(random_seed)\n",
    "        self._W = self._random_state.uniform(-2,2,size=(inputs, outputs))\n",
    "        self._b = self._random_state.uniform(-2,2,size=(outputs,))\n",
    "        self.params = [self._W, self._b]\n",
    "        self.grads = [np.zeros_like(self._W), np.zeros_like(self._b)]\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return inputs @ self._W + self._b[np.newaxis,:]\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        # gradient in respect to W\n",
    "        w_grad = inputs[:,:,np.newaxis] * gradients[:,np.newaxis,:]  # examples, inputs, outputs\n",
    "        np.add(self.grads[0], np.sum(w_grad, axis=0), out=self.grads[0])  # inputs, outputs\n",
    "        # gradient in respect to b\n",
    "        b_grad = gradients  # examples, outputs\n",
    "        np.add(self.grads[1], np.sum(b_grad, axis=0), out=self.grads[1])  # outputs\n",
    "        # gradient in respect to inputs\n",
    "        in_grad = self._W[np.newaxis,:,:] * gradients[:,np.newaxis,:] + np.sign(self._b)[np.newaxis, np.newaxis, :]  # examples, inputs, outputs\n",
    "        return np.sum(in_grad, axis=2) # examples, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small space for optimization. We may tell NumPy to use existing memory instead of creating ita gain and again at every pass. This optimization comes handy, as the dense layer is the most computationally demanding layer. The following code is equivalent to the previous one but uses cache memory in the size of *(examples,inputs,outputs)* to speed up the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self,inputs, outputs, random_seed=None):\n",
    "        self._random_state = np.random.RandomState(random_seed)\n",
    "        self._W = self._random_state.uniform(-2,2,size=(inputs, outputs))\n",
    "        self._b = self._random_state.uniform(-2,2,size=(outputs,))\n",
    "        self.params = [self._W, self._b]\n",
    "        self.grads = [np.zeros_like(self._W), np.zeros_like(self._b)]\n",
    "        self._cache = None\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return inputs @ self._W + self._b[np.newaxis,:]\n",
    "    \n",
    "    def gradient(self, inputs, gradients):\n",
    "        # create the cache\n",
    "        if self._cache is None or self._cache.shape[0] != inputs.shape[0]:\n",
    "            self._cache = np.ndarray((inputs.shape[0],inputs.shape[1], gradients.shape[1]))\n",
    "        # gradient in respect to W\n",
    "        w_grad = np.multiply(inputs[:,:,np.newaxis], gradients[:,np.newaxis,:], out=self._cache)  # examples, inputs, outputs\n",
    "        np.add(self.grads[0], np.sum(w_grad, axis=0), out=self.grads[0])  # inputs, outputs\n",
    "        # gradient in respect to b\n",
    "        b_grad = gradients  # examples, outputs\n",
    "        np.add(self.grads[1], np.sum(b_grad, axis=0), out=self.grads[1])  # outputs\n",
    "        # gradient in respect to inputs\n",
    "        in_grad = np.multiply(self._W[np.newaxis,:,:], gradients[:,np.newaxis,:], out=self._cache)  # examples, inputs, outputs\n",
    "        return np.sum(in_grad, axis=2) # examples, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the layers we need. Last thing we need to refactor is the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent optimizer\n",
    "\n",
    "This refactoring will be very fast. We still don't have the `Model` class, but I may tell you in advance that it would have `layers` property, that would be a list of individual layers. As each layer has `params` and `grads` attributes (that's why they are even in the softmax layer), the optimizer can use that. The optimizer will have `optim` method, that accepts the model and perform one step of the gradient descent algorithm.\n",
    "\n",
    "We will have better optimizers later on, that's why I wanted to export it outside of the model itself. Our gradient descent algorithm can look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def optim(self, model):\n",
    "        for layer in model.layers:\n",
    "            for params, grad in zip(layer.params, layer.grads):\n",
    "                np.add(params, - self.learning_rate * grad, out=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We are almost finished. Now we will define `Model` class, which would represent the model itself. It will contain layers in the `layers` attribute, as I mentioned before. Other than that, It will have standard methods we have seen in the logistic regression.\n",
    "\n",
    "The prediction is done layer by layer, the code can look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "current_grad = loss.gradient(batch_target, outputs[-1])\n",
    "for layer, layer_input in zip(self.layers[::-1], outputs[-2::-1]):\n",
    "    current_grad = layer.gradient(layer_input, current_grad)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remember the outputs of layers (there are inputs to the following layers) in the `outputs` variable and use them during the backpropagation phase. Firstly, we will compute the gradient of the loss and then pass it to the `gradient` method of the last layer. The gradient will propagate through the layers (from the last to the first layer) until we have gradients of weights. As our code accumulates the gradients of the weights (notice the `np.add` call in all the classes above), we need to zero the gradients first. The code can look similar to this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "self.zero_grad()\n",
    "current_grad = loss.gradient(batch_target, outputs[-1])\n",
    "for layer, layer_input in zip(self.layers[::-1], outputs[-2::-1]):\n",
    "    current_grad = layer.gradient(layer_input, current_grad)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we call our optimizer to update the weights. The rest of the code should be straightforward, as it is just copied from the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, input_dim, classes, loss, metrices = [], random_seed = None):\n",
    "        self._rand = np.random.RandomState(random_seed);\n",
    "        self.loss = loss\n",
    "        self.metrices = metrices\n",
    "        self.layers = [\n",
    "            DenseLayer(input_dim, classes, self._rand.randint(100000)),\n",
    "            SoftmaxLayer()\n",
    "        ]\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for layer in self.layers:\n",
    "            for grad in layer.grads:\n",
    "                grad.fill(0)\n",
    "    \n",
    "    def fit(self, X, y, optimizer, Xtest=None, ytest=None, epochs=100, batch_size=32, progress=False):\n",
    "        # get how many data we have\n",
    "        n_train_data = len(X)\n",
    "        n_test_data = 1 if ytest is None else len(ytest)\n",
    "        # store gradients and losses\n",
    "        train_losses = np.zeros((epochs,))\n",
    "        test_losses = np.zeros((epochs,))\n",
    "        train_metrices = np.zeros((len(self.metrices), epochs))\n",
    "        test_metrices = np.zeros((len(self.metrices), epochs))\n",
    "        # decide whatever to log progress\n",
    "        epoch_counter = progressbar(range(epochs)) if progress else range(epochs)\n",
    "        # Learning\n",
    "        outputs = [None] * (len(self.layers) + 1)\n",
    "        for epoch in epoch_counter:\n",
    "            # shuffle the data\n",
    "            permutation = self._rand.permutation(n_train_data)\n",
    "            # for each batch\n",
    "            for batch_start in range(0, n_train_data, batch_size):\n",
    "                # get batch\n",
    "                batch_data = X[permutation[batch_start:batch_start+batch_size]]\n",
    "                batch_target = y[permutation[batch_start:batch_start+batch_size]]\n",
    "                # forward pass\n",
    "                outputs[0] = batch_data\n",
    "                for layer, i in zip(self.layers, range(len(self.layers))):\n",
    "                    outputs[i+1] = layer(outputs[i])\n",
    "                # backward pass\n",
    "                self.zero_grad()\n",
    "                current_grad = self.loss.gradient(batch_target, outputs[-1])\n",
    "                for layer, layer_input in zip(self.layers[::-1], outputs[-2::-1]):\n",
    "                    current_grad = layer.gradient(layer_input, current_grad)\n",
    "                # update the weights\n",
    "                optimizer.optim(self)\n",
    "                # store loss\n",
    "                train_losses[epoch] += np.sum(self.loss(batch_target, outputs[-1]))\n",
    "                # compute the metrices\n",
    "                for metric in self.metrices:\n",
    "                    metric(batch_target, outputs[-1])\n",
    "            # store train metrices\n",
    "            for num_metric, metric in enumerate(self.metrices):\n",
    "                train_metrices[num_metric, epoch] = metric.summary()\n",
    "                \n",
    "            # evaluate on the test set\n",
    "            if Xtest is not None and ytest is not None:\n",
    "                # for each batch\n",
    "                for batch_start in range(0, n_test_data, batch_size):\n",
    "                    # get batch\n",
    "                    batch_data = Xtest[batch_start:batch_start+ batch_size]\n",
    "                    batch_target = ytest[batch_start:batch_start + batch_size]\n",
    "                    # predict the data\n",
    "                    prediction = self.predict(batch_data)\n",
    "                    # store loss\n",
    "                    test_losses[epoch] += np.sum(self.loss(batch_target, prediction))\n",
    "                    # compute the metrices\n",
    "                    for metric in self.metrices:\n",
    "                        metric(batch_target, prediction)\n",
    "                # store test metrices\n",
    "                for num_metric, metric in enumerate(self.metrices):\n",
    "                    test_metrices[num_metric, epoch] = metric.summary()\n",
    "          \n",
    "        results = {\n",
    "            \"train_loss\": train_losses / n_train_data, \n",
    "            \"test_loss\": test_losses / n_test_data,      \n",
    "        }\n",
    "        results.update({f\"train_{metric.name}\": train_metrices[num_metric] for num_metric in range(len(self.metrices))})\n",
    "        results.update({f\"test_{metric.name}\": test_metrices[num_metric] for num_metric in range(len(self.metrices))})\n",
    "        return results\n",
    "    \n",
    "    def predict(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some doubts about which parameters should be in the constructor and which one in the `fit` method, so don't be afraid of the differences with the model in the previous notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now let's put out model in action. First, we need the data. Notice that I don't pad them by 1 this time - the bias term in the dense network cares of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "y, X = y.astype(int), X.reshape(-1, 784)\n",
    "X[X < 128] = 0\n",
    "X[X > 0] = 1\n",
    "train_data, test_data, train_target, test_target = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need our accuracy metric. As we modified the output of the model a little bit (we return probability distribution instead of class), the accuracy is a bit different than in the previous notebook. I ass `np.argmax` call to get the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyMetric:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name or \"accuracy\"\n",
    "        self.correct = 0\n",
    "        self.num = 0\n",
    "    def __call__(self, target, predicted):\n",
    "        self.correct += np.sum(np.argmax(predicted,axis=1) == target)\n",
    "        self.num += len(target)\n",
    "    def summary(self):\n",
    "        acc = self.correct / self.num\n",
    "        self.correct = 0\n",
    "        self.num = 0\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may create the optimizer, model, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (400 of 400) |######################| Elapsed Time: 0:23:45 Time:  0:23:45\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(learning_rate=0.001)\n",
    "model = MulticlassLogisticRegression(784, 10, loss=CategoricalCrossEntropyLoss(), metrices=[AccuracyMetric()], random_seed=42)\n",
    "result = model.fit(train_data, train_target, optimizer, test_data, test_target, epochs=400, batch_size=128, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember, the running time of 10 logistic regression were around 11 minutes in the previous notebook. It may be surprising the 27 minutes in this case. The fact is, that we compute something, we don't need to right now. When we call the `gradient` method on the dense layer, it returns the gradient for the previous layer - but we don't have any. This computation is the most demanding one and accounts for the additional 15 minutes of the training. I could just ignore it and do not implement it, but we are going to need it in the following notebook.\n",
    "\n",
    "Let's now look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9334285714285714, Test accuracy: 0.9087142857142857\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {result['train_accuracy'][-1]}, Test accuracy: {result['test_accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(result['train_loss'], label=\"train loss\")\n",
    "plt.plot(result['test_loss'], label=\"test loss\")\n",
    "plt.yscale('log')\n",
    "ticks = [0.16, 0.225, 0.32, 0.45, 0.64, 0.9, 1.28, 1.8, 2.56, 3.6, 5.12]\n",
    "plt.yticks(ticks=ticks, labels=ticks)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(result['train_accuracy'], label=\"train accuracy\")\n",
    "plt.plot(result['test_accuracy'], label=\"test accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we may see, the accuracies are close to the one-vs-rest approach we used in the last notebook. This is correct, as we just refactor the implementation from the last notebook - under the hood, it is still the same model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we move on\n",
    "\n",
    "We are finally going to see real neural networks in the following notebook. But before you open it, I have one request.\n",
    "\n",
    "> **Please make sure you understand everything in this notebook.**\n",
    "\n",
    "Even read this notebook once again. Make sure you are fully aware of activation functions, softmax, dense layer, losses, optimizers and you really know, how the gradients are computed along the way. Makes also sure to understand how weights, layers, models, optimizers, losses assembly together to create the resulting trained model.\n",
    "\n",
    "This is probably the hardest and technical notebook you will see and I know it was challenging. Please, if you had problems with the formulations or you were missing something, don't hesitate to contact me. The concepts discussed here will be the fundamentals of neural networks that we are going to use over and over again and you should understand them before moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "- \\[1\\] The Softmax Function Derivative, Stephen Oman, 17th June 2019, [online](https://aimatters.wordpress.com/2019/06/17/the-softmax-function-derivative/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

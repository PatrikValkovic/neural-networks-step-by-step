{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing, sklearn.datasets, sklearn.model_selection\n",
    "import timeit\n",
    "from progressbar import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be dealing with multiclass classification. We will have finally model, that can distinguish between all the numbers from the MNIST dataset and we will not need to deal with 4 and 9 only. The proper way of handling this problem is to use *softmax* function. I will show different approaches before, so we can compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need the data. The template is still the same, so I will not describe it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = sklearn.datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "data = data.reshape(-1, 784)\n",
    "data[data < 128] = 0\n",
    "data[data > 0] = 1\n",
    "data = np.hstack([data, np.ones((data.shape[0],1))])\n",
    "train_data, test_data, train_target, test_target = sklearn.model_selection.train_test_split(data, target.astype(int), test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "If you remember, we dealt with this problem in one of the previous notebook, when we were talking about perceptron algorithm. Just as a reminder, let's do it once again here, co we may compare the reults. I moved it into separate class, so I dont need to copy-paste it here once again. If you are interested, it is in the [src/perceptron.py](src/perceptron.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9741020408163266, Test accuracy: 0.911\n"
     ]
    }
   ],
   "source": [
    "from src.perceptron_05 import multiclass_perceptron\n",
    "\n",
    "train_acc, test_acc = multiclass_perceptron(train_data, train_target, test_data, test_target, iters=500, random_state=42)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results don't tell much yet. The test accuracy is maybe too low compare to the train accuracy, but we will se how different models will behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neuron_05 import Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss:\n",
    "    def __call__(self, target, predicted):\n",
    "        return np.sum(-target * np.log(np.maximum(predicted, 1e-15)) - (1 - target) * np.log(np.maximum(1 - predicted, 1e-15)), axis=0)\n",
    "    def gradient(self, target, predicted):\n",
    "        return - target / (np.maximum(predicted, 1e-15)) + (1 - target) / (np.maximum(1 - predicted, 1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (200 of 200) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:46 Time:  0:00:46\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:51 Time:  0:00:51\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:30 Time:  0:00:30\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:17 Time:  0:00:17\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:17 Time:  0:00:17\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:27 Time:  0:00:27\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:17 Time:  0:00:17\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:22 Time:  0:00:22\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:30 Time:  0:00:30\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:18 Time:  0:00:18\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:23 Time:  0:00:23\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:27 Time:  0:00:27\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:27 Time:  0:00:27\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:29 Time:  0:00:29\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:27 Time:  0:00:27\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:23 Time:  0:00:23\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:29 Time:  0:00:29\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:28 Time:  0:00:28\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:25 Time:  0:00:25\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:25 Time:  0:00:25\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:29 Time:  0:00:29\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:41 Time:  0:00:41\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:43 Time:  0:00:43\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:48 Time:  0:00:48\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:40 Time:  0:00:40\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:44 Time:  0:00:44\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:45 Time:  0:00:45\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:40 Time:  0:00:40\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:45 Time:  0:00:45\n",
      "100% (200 of 200) |######################| Elapsed Time: 0:00:40 Time:  0:00:40\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "models = np.empty((10,10), dtype=object)\n",
    "for i in range(10):\n",
    "    for j in range(i):\n",
    "        models[i][j] = Neuron(BCELoss(), epochs=200, learning_rate=0.001, batch_size=128, random_state=42+i*10+j)\n",
    "        mask = np.logical_or(train_target == i, train_target == j)\n",
    "        current_X = train_data[mask]\n",
    "        current_y = (train_target[mask] - j) / (i - j)\n",
    "        models[i][j].fit(current_X, current_y, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "train_predictions = np.zeros((train_target.shape[0], 10), dtype=int)\n",
    "test_predictions = np.zeros((test_target.shape[0], 10), dtype=int)\n",
    "for i in range(10):\n",
    "    for j in range(i):\n",
    "        prediction = np.around(models[i][j].predict(train_data))\n",
    "        train_predictions[prediction == 0, j] += 1\n",
    "        train_predictions[prediction == 1, i] += 1\n",
    "        prediction = np.around(models[i][j].predict(test_data))\n",
    "        test_predictions[prediction == 0, j] += 1\n",
    "        test_predictions[prediction == 1, i] += 1\n",
    "train_predictions = train_predictions.argmax(axis=1)\n",
    "test_predictions = test_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = sklearn.metrics.accuracy_score(train_target, train_predictions)\n",
    "test_acc = sklearn.metrics.accuracy_score(test_target, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.945, Test accuracy: 0.9122857142857143\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "train_predictions = np.zeros((train_target.shape[0], 10), dtype=float)\n",
    "test_predictions = np.zeros((test_target.shape[0], 10), dtype=float)\n",
    "for i in range(10):\n",
    "    for j in range(i):\n",
    "        prediction = models[i][j].predict(train_data)\n",
    "        train_predictions[:, j] += 1-prediction\n",
    "        train_predictions[:, i] += prediction\n",
    "        prediction = models[i][j].predict(test_data)\n",
    "        test_predictions[:, j] += 1-prediction\n",
    "        test_predictions[:, i] += prediction\n",
    "train_predictions = train_predictions.argmax(axis=1)\n",
    "test_predictions = test_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = sklearn.metrics.accuracy_score(train_target, train_predictions)\n",
    "test_acc = sklearn.metrics.accuracy_score(test_target, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9465714285714286, Test accuracy: 0.9174761904761904\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
